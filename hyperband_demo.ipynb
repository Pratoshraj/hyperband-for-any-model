{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperband_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgwEPWBo1wKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class hyperband:\n",
        "\n",
        "    def __init__(self,space):\n",
        "        \"\"\" The search space components, initialised by the user \"\"\"\n",
        "\n",
        "        self.search_space = space\n",
        "\n",
        "\n",
        "\n",
        "    def __sample(self,n_samples):\n",
        "\n",
        "        \"\"\" It draws a sample 'n_samples' times from the search space uniformly\n",
        "\n",
        "            Arguments \n",
        "              n_samples : no. of points to sample from the search space\n",
        "                        dtype - int\n",
        "\n",
        "            Returns\n",
        "              config : sampled hyperparameter configurations\n",
        "                        dtype - numpyarray        \n",
        "        \"\"\"\n",
        "\n",
        "        config = np.array([np.random.choice(self.search_space[val],n_samples,replace=True) for val in self.search_space.keys()])\n",
        "        return np.transpose(config)\n",
        "\n",
        "\n",
        "    def search(self,model_definition,max_iter=81,eta=3,skip_last=1,using_loss=False):\n",
        "      \n",
        "        \"\"\" Assigns the number of unique brackets, number of resources and configs, implements the successive halving\n",
        "        \n",
        "            Arguments\n",
        "              model_definition : a user defined function which contains the definition of the model\n",
        "                                \n",
        "              max_iter : maximum no. of iterations allowed for one hyper-parameter configuration,    dtype - int    default - 81\n",
        "\n",
        "              eta : reduction rate of configuration in each successive halving,   dtype - int   default - 3\n",
        "\n",
        "              skip_last : if 1 skips the last bracket and vice-versa,   dtype - int  default - 1\n",
        "\n",
        "              using_loss : if true uses loss function of the model to evaluate in sucessive halving and if not uses val-metric of the model,   dtype - bool   default - False\n",
        "\n",
        "\n",
        "            Returns\n",
        "              best : the best hyper-parameter configuration \n",
        "        \"\"\"\n",
        "\n",
        "        logeta = lambda x: math.log(x) / math.log(eta)\n",
        "        s_max = int(logeta(max_iter))\n",
        "        B = (s_max + 1) * max_iter\n",
        "\n",
        "        result = np.array([])\n",
        "        best_config = np.array([])\n",
        "\n",
        "        ## this loop denotes the no. of unique run of successive halving\n",
        "        for s in reversed(range(s_max + 1)):\n",
        "\n",
        "            print('\\n  Current bracket number - ', s)\n",
        "\n",
        "            if skip_last:\n",
        "                if s == 0: break\n",
        "\n",
        "            n = int(math.ceil(int(B / max_iter / (s + 1)) * eta ** s))  # number of configurations to sample for at starting of given bracket\n",
        "            r = max_iter * eta ** (-s)  # number of resources at starting for given bracket\n",
        "\n",
        "            T = self.__sample(n)  # sampling from the search space\n",
        "            metric = np.array([])\n",
        "\n",
        "            ## this loop runs the successive halving for a given bracket\n",
        "            for i in range(s + 1):\n",
        "\n",
        "                n_i = n * eta ** (-i)  # no. of configs for given successive halving\n",
        "                r_i = r * eta ** (i)  # no. of resources for given successive halving\n",
        "                val_metric = np.array([model_definition(r_i,t) for t in T])  # getting the val_metric for each config\n",
        "                if using_loss: T = np.array([T[i] for i in reversed(np.argsort(val_metric)[int(n / eta):])])  # implementing the successive halving\n",
        "                else: T = np.array([T[i] for i in np.argsort(val_metric)[:int(n / eta)]])\n",
        "                metric = np.append(metric,np.max(val_metric))\n",
        "\n",
        "                print('\\n\\n \\t number of reduction/successive halving done - ', i)\n",
        "\n",
        "            best_config = np.append(best_config, T[0])  # keeping track of the best config from each bracket\n",
        "            result = np.append(result,metric[-1])\n",
        "\n",
        "        best = best_config[np.argmax(result)]\n",
        "        print('\\n\\n the best configuration - ', best)\n",
        "\n",
        "        return best  # return the best config from all the brackets by max val_metric\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmq4CHH317S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## defining the search space\n",
        "\n",
        "space = {'lr': np.array([0.00001,0.00005,0.00008,0.0001,0.0005,0.0008,0.001,0.005,0.008,0.01]),\n",
        "                  'beta1': np.arange(0.86,0.94,0.02),\n",
        "                  'beta2': np.arange(0.997,0.999,0.001),\n",
        "                  'loss': np.array(['focal_loss','cross_entropy'])}\n",
        "hyp = hyperband(space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qRKjXaJ6d59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5ba8007-afae-4e08-99a0-dab48223a6e9"
      },
      "source": [
        "## since I'm using it for segmentation, I've defined my own models,loss functions and metrics\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Add,Input,MaxPooling2D,concatenate,BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.applications import *\n",
        "from keras.layers.convolutional import Conv2D,Conv2DTranspose\n",
        "from keras.layers.core import Activation\n",
        "\n",
        "\n",
        "class UNET:\n",
        "\n",
        "    class unet:\n",
        "        \"\"\" Unet architecture\n",
        "\n",
        "               Usage :\n",
        "                   unet = Semantic_Segmentation.models.UNET.unet(input_shape,no_classes,regularizer,summary)\n",
        "                   model = unet.build()\n",
        "\n",
        "               # Arguments\n",
        "                   input_shape : size of the input image ,in tuple.\n",
        "                   n_classes : the number of target class.\n",
        "                               dtype --> int\n",
        "                   regularizer : the regularizing value, it uses L2 regularizers on the kernel/filters.\n",
        "                               dtype --> float   default -->None\n",
        "                   summary : If True prints the model summary\n",
        "                                default --> True\n",
        "           \"\"\"\n",
        "        build = lambda self: self.__architecture()\n",
        "        weight_decay = lambda self, x: None if x == None else l2(x)\n",
        "        batchnorm = lambda self, x: BatchNormalization(beta_regularizer=l2(0.001),\n",
        "                                                       gamma_regularizer=l2(0.001)) if x else Activation('linear')\n",
        "\n",
        "        def __init__(self, input_shape, n_classes, regularizer=None, BatchNorm=True, summary=True):\n",
        "            self.input_shape = input_shape\n",
        "            self.n_classes = n_classes\n",
        "            self.regularizer = regularizer\n",
        "            self.BatchNorm = BatchNorm\n",
        "            self.summary = summary\n",
        "\n",
        "        def __architecture(self):\n",
        "            input = Input(self.input_shape)\n",
        "\n",
        "            conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(input)\n",
        "            conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv1)\n",
        "            batchnorm1 = self.batchnorm(self.BatchNorm)(conv1)\n",
        "            pool1 = MaxPooling2D(pool_size=(2, 2))(batchnorm1)\n",
        "\n",
        "            conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(pool1)\n",
        "            conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv2)\n",
        "            batchnorm2 = self.batchnorm(self.BatchNorm)(conv2)\n",
        "            pool2 = MaxPooling2D(pool_size=(2, 2))(batchnorm2)\n",
        "\n",
        "            conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(pool2)\n",
        "            conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv3)\n",
        "            batchnorm3 = self.batchnorm(self.BatchNorm)(conv3)\n",
        "            pool3 = MaxPooling2D(pool_size=(2, 2))(batchnorm3)\n",
        "\n",
        "            conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(pool3)\n",
        "            conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv4)\n",
        "            batchnorm4 = self.batchnorm(self.BatchNorm)(conv4)\n",
        "            pool4 = MaxPooling2D(pool_size=(2, 2))(batchnorm4)\n",
        "\n",
        "            conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(pool4)\n",
        "            conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv5)\n",
        "            batchnorm5 = self.batchnorm(self.BatchNorm)(conv5)\n",
        "            up5 = Conv2DTranspose(512, 4, strides=(2, 2), padding='same',\n",
        "                                  kernel_regularizer=self.weight_decay(self.regularizer), name='upsample_5')(batchnorm5)\n",
        "\n",
        "            merge6 = concatenate([batchnorm4, up5], axis=3)\n",
        "            conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(merge6)\n",
        "            conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv6)\n",
        "            batchnorm6 = self.batchnorm(self.BatchNorm)(conv6)\n",
        "            up6 = Conv2DTranspose(256, 4, strides=(2, 2), padding='same',\n",
        "                                  kernel_regularizer=self.weight_decay(self.regularizer), name='upsample_6')(batchnorm6)\n",
        "\n",
        "            merge7 = concatenate([batchnorm3, up6], axis=3)\n",
        "            conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(merge7)\n",
        "            conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv7)\n",
        "            batchnorm7 = self.batchnorm(self.BatchNorm)(conv7)\n",
        "            up7 = Conv2DTranspose(128, 4, strides=(2, 2), padding='same',\n",
        "                                  kernel_regularizer=self.weight_decay(self.regularizer), name='upsample_7')(batchnorm7)\n",
        "\n",
        "            merge8 = concatenate([batchnorm2, up7], axis=3)\n",
        "            conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "            conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "            batchnorm8 = self.batchnorm(self.BatchNorm)(conv8)\n",
        "            up8 = Conv2DTranspose(64, 4, strides=(2, 2), padding='same',\n",
        "                                  kernel_regularizer=self.weight_decay(self.regularizer), name='upsample_8')(batchnorm8)\n",
        "\n",
        "            merge9 = concatenate([batchnorm1, up8], axis=3)\n",
        "            conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(merge9)\n",
        "            conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv9)\n",
        "            conv9 = Conv2D(self.n_classes, 1, activation='softmax', padding='same', kernel_initializer='he_normal',\n",
        "                           kernel_regularizer=self.weight_decay(self.regularizer))(conv9)\n",
        "            #op = Activation('softmax', name='softmax')(conv9)\n",
        "\n",
        "            model = Model(input=input, output=conv9, name='Unet')\n",
        "            if self.summary: print(model.summary())\n",
        "            return model\n",
        "\n",
        "\n",
        "class FCN:\n",
        "    \"\"\" Available models --> fcn32, fcn16, fcn8\n",
        "\n",
        "        All the three avilable with vgg16,vgg19,resnet50\n",
        "    \"\"\"\n",
        "\n",
        "    class fcn32:\n",
        "\n",
        "        \"\"\" FCN32 architecture, it doesn't use any skip connections and upsamples the image by the scale of 32.\n",
        "\n",
        "            Usage :\n",
        "                FCN32 = Semantic_Segmentation.models.FCN.fcn32(input_shape,no_classes,base_model_name,pretrained_weights,regularizer,summary)\n",
        "                model = FCN32.build()\n",
        "\n",
        "            # Arguments\n",
        "                input_shape : size of the input image ,in tuple.\n",
        "                n_classes : the number of target class.\n",
        "                            dtype --> int\n",
        "                base_model : name of the pre-trained cnn model on top of which FCN is built.\n",
        "                            dtype --> string  default --> 'vgg16'\n",
        "                weight_path : path to the pre_trained weight files.\n",
        "                            dtype --> string  default --> 'imagenet'\n",
        "                regularizer : the regularizing value, it uses L2 regularizers on the kernel/filters.\n",
        "                            dtype --> float   default -->None\n",
        "                summary : If True prints the model summary\n",
        "                                default --> True\n",
        "        \"\"\"\n",
        "        weight_decay = lambda self,x: l2(x) if type(x)==int else None\n",
        "        build = lambda self: self.__decoder(self.encoder())\n",
        "\n",
        "        def __init__(self,input_shape,n_classes,base_model='vgg16',weight_path='imagenet',regularizer = None,summary=True):\n",
        "            self.base_model = base_model\n",
        "            self.input_shape = input_shape\n",
        "            self.n_classes = n_classes\n",
        "            self.weightpath = weight_path\n",
        "            self.regularizer = regularizer\n",
        "            self.summary = summary\n",
        "\n",
        "\n",
        "        def encoder(self):\n",
        "\n",
        "            \"\"\" Builds the encoder layer on top of the given pre-trained CNN model\n",
        "\n",
        "                # Returns\n",
        "                    model_en : the architecture of the encoder part\n",
        "            \"\"\"\n",
        "            if self.base_model == 'vgg16':\n",
        "                base = vgg16.VGG16(include_top=False, weights=self.weightpath, pooling=None, input_shape=self.input_shape)\n",
        "            elif self.base_model == 'vgg19':\n",
        "                base = vgg19.VGG19(include_top=False, weights=self.weightpath, pooling=None, input_shape=self.input_shape)\n",
        "            else: base = resnet50.ResNet50(include_top=False, weights=self.weightpath, pooling=None, input_shape=self.input_shape)\n",
        "\n",
        "            layer_encoder = Conv2D(4096, (7, 7), padding='same', activation='relu', kernel_regularizer=self.weight_decay(self.regularizer),\n",
        "                                   name='conv_en1')(base.output)\n",
        "            layer_encoder = Conv2D(4096, (1, 1), padding='same', activation='relu', kernel_regularizer=self.weight_decay(self.regularizer),\n",
        "                                   name='conv_en2')(layer_encoder)\n",
        "\n",
        "            encoder_model = Model(base.input,layer_encoder)\n",
        "            return encoder_model\n",
        "\n",
        "\n",
        "        def __decoder(self,model_en):\n",
        "\n",
        "            \"\"\" Builds the decoder layer on top of the encoder part.\n",
        "\n",
        "                # Arguments\n",
        "                    model_en : the model architecture of the encoder part\n",
        "\n",
        "                # Returns\n",
        "                    model : the full model architecture, both encoder and decoder combined\n",
        "            \"\"\"\n",
        "            layer_decoder = Conv2D(self.n_classes, (1,1), padding='same', activation='relu', kernel_regularizer=self.weight_decay(self.regularizer),\n",
        "                                   name = 'conv_dec')(model_en.output)\n",
        "            layer_decoder = Conv2DTranspose(self.n_classes, (64,64), strides=(32,32), padding = 'same', kernel_regularizer = self.weight_decay(self.regularizer),\n",
        "                                            name = 'deconv')(layer_decoder)\n",
        "            output = Activation('softmax',name='softmax')(layer_decoder)\n",
        "\n",
        "            model = Model(model_en.input,output,name='FCN32-'+self.base_model)\n",
        "            if self.summary: print(model.summary())\n",
        "            return model\n",
        "\n",
        "\n",
        "        def skip_connections(self,model_en):\n",
        "\n",
        "            \"\"\" Builds the skip connections based on the pre-trained CNN models for FCN16 and FCN8.\n",
        "                NOTE- FCN32 doesnt use this function, its a base for other class/FCN16,FCN8\n",
        "\n",
        "                # Arguments:\n",
        "                    model_en : the model architecture of the encoder part\n",
        "            \"\"\"\n",
        "            if self.base_model == 'resnet50': skip_1,skip_2 = model_en.get_layer(model_en.layers[112].name).output, model_en.get_layer(model_en.layers[50].name).output\n",
        "            else: skip_1,skip_2 = model_en.get_layer('block4_pool').output, model_en.get_layer('block3_pool').output\n",
        "            return skip_1,skip_2\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    class fcn16(fcn32):\n",
        "\n",
        "        \"\"\" FCN16 architecture, it uses one skip connection and upsamples the image by the scale of 16.\n",
        "\n",
        "            Usage :\n",
        "                FCN16 = Semantic_Segmentation.models.FCN.fcn16(input_shape,no_classes,base_model_name,pretrained_weights,regularizer,summary)\n",
        "                model = FCN16.build()\n",
        "\n",
        "            # Arguments\n",
        "                input_shape : size of the input image ,in tuple.\n",
        "                n_classes : the number of target class.\n",
        "                            dtype --> int\n",
        "                base_model : name of the pre-trained cnn model on top of which FCN is built.\n",
        "                            dtype --> string  default --> 'vgg16'\n",
        "                weight_path : path to the pre_trained weight files.\n",
        "                            dtype --> string  default --> 'imagenet'\n",
        "                regularizer : the regularizing value, it uses L2 regularizers on the kernel/filters.\n",
        "                            dtype --> float   default -->None\n",
        "                summary : If True prints the model summary\n",
        "                                default --> True\n",
        "        \"\"\"\n",
        "\n",
        "        ## NOTE : It wraps the properties of FCN32, same arguments and encoder part but it uses diff decoder function\n",
        "        ##since the decoder includes skip connection.\n",
        "        build = lambda self: self.__decoder(super().encoder())\n",
        "\n",
        "        def __decoder(self,model_en):\n",
        "\n",
        "            skip,_ = super().skip_connections(model_en)\n",
        "\n",
        "            layer_decoder = Conv2DTranspose(skip.get_shape().as_list()[-1], (4, 4), strides=(2, 2), padding='same',\n",
        "                                            kernel_regularizer=super().weight_decay(self.regularizer), name='deconv1')(model_en.output)\n",
        "            layer_decoder = Add(name='skip1')([layer_decoder, skip])\n",
        "            layer_decoder = Conv2DTranspose(self.n_classes, (32,32), strides=(16, 16), padding='same',\n",
        "                                            kernel_regularizer=super().weight_decay(self.regularizer), name='deconv3')(layer_decoder)\n",
        "            output = Activation('softmax',name='softmax')(layer_decoder)\n",
        "\n",
        "            model = Model(model_en.input, output,name='FCN16-'+self.base_model)\n",
        "            if self.summary: print(model.summary())\n",
        "            return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    class fcn8(fcn32):\n",
        "\n",
        "        \"\"\" FCN8 architecture, it uses two skip connections and upsamples the image by the scale of 8, preserves most of the information.\n",
        "\n",
        "            Usage :\n",
        "                FCN8 = Semantic_Segmentation.models.FCN.fcn8(input_shape,no_classes,base_model_name,pretrained_weights,regularizer,summary)\n",
        "                model = FCN8.build()\n",
        "\n",
        "            # Arguments\n",
        "                input_shape : size of the input image ,in tuple.\n",
        "                n_classes : the number of target class.\n",
        "                            dtype --> int\n",
        "                base_model : name of the pre-trained cnn model on top of which FCN is built.\n",
        "                            dtype --> string  default --> 'vgg16'\n",
        "                weight_path : path to the pre_trained weight files.\n",
        "                            dtype --> string  default --> 'imagenet'\n",
        "                regularizer : the regularizing value, it uses L2 regularizers on the kernel/filters.\n",
        "                            dtype --> float   default -->None\n",
        "                summary : If True prints the model summary\n",
        "                                default --> True\n",
        "        \"\"\"\n",
        "\n",
        "        ## NOTE : It wraps the properties of FCN32, same arguments and encoder part but it uses diff decoder function\n",
        "        ##since the decoder includes 2 skip connections.\n",
        "\n",
        "        build = lambda self: self.__decoder(super().encoder())\n",
        "\n",
        "        def __decoder(self,model_en):\n",
        "\n",
        "            skip_1,skip_2 = super().skip_connections(model_en)\n",
        "\n",
        "            layer_decoder = Conv2DTranspose(skip_1.get_shape().as_list()[-1], (4, 4), strides=(2, 2), padding='same',\n",
        "                                            kernel_regularizer=super().weight_decay(self.regularizer), name='deconv1')(model_en.output)\n",
        "            layer_decoder = Add(name='skip1')([layer_decoder, skip_1])\n",
        "            layer_decoder = Conv2DTranspose(skip_2.get_shape().as_list()[-1], (4, 4), strides=(2, 2), padding='same',\n",
        "                                            kernel_regularizer=super().weight_decay(self.regularizer), name='deconv2')(layer_decoder)\n",
        "            layer_decoder = Add(name='skip2')([layer_decoder, skip_2])\n",
        "            layer_decoder = Conv2DTranspose(self.n_classes, (16, 16), strides=(8, 8), padding='same',\n",
        "                                            kernel_regularizer=super().weight_decay(self.regularizer), name='deconv3')(layer_decoder)\n",
        "            output = Activation('softmax',name='softmax')(layer_decoder)\n",
        "\n",
        "            model = Model(model_en.input,output,name='FCN8-'+self.base_model)\n",
        "            if self.summary: print(model.summary())\n",
        "            return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class focal_loss:\n",
        "\n",
        "    \"\"\" A loss function similar to cross_entropy\n",
        "\n",
        "        # Usage\n",
        "            model.compile('sgd',loss=focal_loss.loss,.......)\n",
        "\n",
        "        # Arguments\n",
        "            class_weights : weights for each class to solve the class imbalance problem.\n",
        "                            dtype --> array   default --> None\n",
        "            pixel_weights : weights for each pixels in order to segment certain part of the image clearly.\n",
        "                            dtype --> array   default --> None\n",
        "    \"\"\"\n",
        "    def c_weights(self,x):\n",
        "      try:\n",
        "        if list(x)!=None: return x\n",
        "      except TypeError: return int('1')\n",
        "\n",
        "    def p_weights(self,x):\n",
        "      try:\n",
        "        if list(x)!=None: return x\n",
        "      except TypeError: return int('1')  \n",
        "\n",
        "\n",
        "\n",
        "    clipping = lambda self,x: K.clip(x, K.epsilon(), 1.-K.epsilon())\n",
        "\n",
        "\n",
        "    def __init__(self,class_weights=None, pixel_weights=None, gamma=2):\n",
        "        self.class_weights = class_weights\n",
        "        self.gamma = gamma\n",
        "        self.pixel_weights = pixel_weights\n",
        "\n",
        "    def loss(self,y_true,y_pred):\n",
        "\n",
        "        \"\"\" executes the focal loss\n",
        "\n",
        "            # Arguments\n",
        "                y_true : true class values\n",
        "                y_pred : predicted class values from the model\n",
        "            # Returns\n",
        "                fl : mean focal loss for the given batch\n",
        "         \"\"\"\n",
        "        y_pred = self.clipping(y_pred)\n",
        "        fl = -(K.sum((self.c_weights(self.class_weights) * K.pow(1.-y_pred,self.gamma) * (y_true * K.log(y_pred))),axis=-1))\n",
        "        fl = K.sum((self.p_weights(self.pixel_weights) * fl),axis=(1,2))\n",
        "        fl = K.mean(fl, axis=0)\n",
        "        return fl/100\n",
        "\n",
        "\n",
        "\n",
        "class cross_entropy(focal_loss):\n",
        "\n",
        "    \"\"\" Categorical cross_entropy\n",
        "        NOTE : for binary classification it uses softmax instead sigmoid\n",
        "\n",
        "        # Usage\n",
        "            model.compile('sgd',loss=cross_entropy.loss,.......)\n",
        "\n",
        "        # Arguments\n",
        "            class_weights : weights for each class to solve the class imbalance problem.\n",
        "                            dtype --> array   default --> None\n",
        "            pixel_weights : weights for each pixels in order to segment certain part of the image clearly.\n",
        "                            dtype --> array   default --> None\n",
        "    \"\"\"\n",
        "\n",
        "    ## NOTE - this class inherits the properties of focal_loss class\n",
        "    def loss(self,y_true,y_pred):\n",
        "\n",
        "        \"\"\" executes the categorical cross-entropy\n",
        "\n",
        "            # Arguments\n",
        "                y_true : true class values\n",
        "                y_pred : predicted class values from the model\n",
        "            # Returns\n",
        "                ce : mean cross-entropy for the given batch\n",
        "        \"\"\"\n",
        "        y_pred = super().clipping(y_pred)\n",
        "        ce = -(K.sum((super().c_weights(self.class_weights) * (y_true * K.log(y_pred))),axis=-1))\n",
        "        ce = K.sum((super().p_weights(self.pixel_weights) * ce),axis=(1,2))\n",
        "        ce = K.mean(ce,axis=0)\n",
        "        return ce/100\n",
        "\n",
        "\n",
        "\n",
        "class dice_loss(focal_loss):\n",
        "\n",
        "    \"\"\" Its similar to IoU, dice_coeff = (2*A^B)/A U B  dice_loss= 1- dice_coeff\n",
        "        # Usage\n",
        "            model.compile('sgd',loss=dice_loss.loss,.......)\n",
        "\n",
        "        # Arguments\n",
        "            class_weights : weights for each class to solve the class imbalance problem.\n",
        "                            dtype --> array   default --> None\n",
        "            pixel_weights : weights for each pixels in order to segment certain part of the image clearly.\n",
        "                            dtype --> array   default --> None\n",
        "    \"\"\"\n",
        "\n",
        "    ## NOTE - this class inherits the properties of focal_loss class\n",
        "    def loss(self,y_true,y_pred):\n",
        "\n",
        "        \"\"\" executes the dice loss\n",
        "\n",
        "            # Arguments\n",
        "                y_true : true class values\n",
        "                y_pred : predicted class values from the model\n",
        "            # Returns\n",
        "                dl : dice loss for the given batch\n",
        "        \"\"\"\n",
        "        y_pred = super().clipping(y_pred)\n",
        "        intersection = K.sum((super().p_weights(self.pixel_weights) * y_true * y_pred),axis=(1,2))\n",
        "        intersection = K.sum((super().c_weights(self.class_weights) * intersection),axis=-1)\n",
        "        union = K.sum( (super().p_weights(self.pixel_weights)*(y_true + y_pred) ),axis=(1,2))\n",
        "        union = K.sum((super().c_weights(self.class_weights) * union),axis=-1)\n",
        "        dl = (1. - ((2*intersection)/union))\n",
        "        return K.mean(dl)\n",
        "\n",
        "\n",
        "class Metrics:\n",
        "\n",
        "    __weighted_method = lambda self,x,y,string,w: (K.sum(x)/K.sum(y)) if string=='inter' else (K.sum(w*x)/K.sum(w*y))\n",
        "    __avg_method = lambda self,x,y,string,w: K.mean(x/y) if string=='intra' else self.__weighted_method(x,y,string,w)\n",
        "\n",
        "\n",
        "    def __metrics_base(self,y_true,y_pred):\n",
        "\n",
        "        \"\"\" Base for all the metrics defined below \"\"\"\n",
        "        y_true,y_pred = K.flatten(tf.math.argmax(y_true,axis=-1)), K.flatten(tf.math.argmax(y_pred,axis=-1))\n",
        "        con_mat = K.cast(tf.math.confusion_matrix(y_true,y_pred), K.floatx())\n",
        "        correct = tf.linalg.diag_part(con_mat)\n",
        "        total = K.sum(con_mat, axis=-1)\n",
        "        return correct,total,con_mat\n",
        "\n",
        "\n",
        "    def accuracy(self,y_true,y_pred):\n",
        "\n",
        "        \"\"\" computes the accuracy\n",
        "\n",
        "            # Arguments\n",
        "                y_true : target value\n",
        "                y_pred : predicted class value\n",
        "            # Returns\n",
        "                acc : overall accuracy\n",
        "        \"\"\"\n",
        "        correct,total,_ = self.__metrics_base(y_true,y_pred)\n",
        "        return ( K.sum(correct) / K.sum(total) )\n",
        "\n",
        "\n",
        "    def IoU(self, y_true, y_pred,average='inter',weights=None):\n",
        "\n",
        "        \"\"\" Intersection over Union , IoU = A^B/(A U B - A^B)\n",
        "           Computes the percentage overlap with the target image.\n",
        "\n",
        "            # Arguments\n",
        "                y_true : target value\n",
        "                y_pred : predicted class value\n",
        "                average : 'inter' --> computes the IoU score overall  'intra' --> computes the score for each calss and computes the average\n",
        "                        'weighted' --> computes the weighted average , useful for imabalanced class.\n",
        "                weights :  only if average is specified 'weighted', weights for the respective classes.\n",
        "            # Returns\n",
        "                IoU score\n",
        "        \"\"\"\n",
        "        _, _, con_mat = self.__metrics_base(y_true, y_pred)\n",
        "        intersection = tf.linalg.diag_part(con_mat)\n",
        "        ground_truth_set = K.sum(con_mat, axis=1)\n",
        "        predicted_set = K.sum(con_mat, axis=0)\n",
        "        union = ground_truth_set + predicted_set - intersection\n",
        "        return self.__avg_method(intersection,union,average,weights)\n",
        "\n",
        "\n",
        "    def recall(self,y_true,y_pred,average='inter',weights=None):\n",
        "\n",
        "        \"\"\" Computes the recall score over each given class and gives the overall score.  recall = TP/TP+FN\n",
        "\n",
        "            # Arguments\n",
        "                y_true : target value\n",
        "                y_pred : predicted class value\n",
        "                average : 'inter' --> computes the recall score overall  'intra' --> computes the score for each calss and computes the average\n",
        "                        'weighted' --> computes the weighted average , useful for imabalanced class.\n",
        "                weights :  only if average is specified 'weighted', weights for the respective classes.\n",
        "            # Returns\n",
        "                recall score\n",
        "        \"\"\"\n",
        "        correct,total,_ = self.__metrics_base(y_true,y_pred)\n",
        "        return self.__avg_method(correct,total,average,weights)\n",
        "\n",
        "\n",
        "    def precision(self,y_true,y_pred,average='inter',weights=None):\n",
        "\n",
        "        \"\"\" Computes the precision over each given class and returns the overall score.  precision = TP/TP+FP\n",
        "\n",
        "            # Arguments\n",
        "                y_true : target value\n",
        "                y_pred : predicted class value\n",
        "                average : 'inter' --> computes the precision score overall  'intra' --> computes the score for each calss and computes the average\n",
        "                        'weighted' --> computes the weighted average , useful for imabalanced class.\n",
        "                weights :  only if average is specified 'weighted', weights for the respective classes.\n",
        "            # Returns\n",
        "                precision score\n",
        "        \"\"\"\n",
        "        correct,_,con_mat = self.__metrics_base(y_true,y_pred)\n",
        "        total = K.sum(con_mat,axis=0)\n",
        "        return self.__avg_method(correct,total,average,weights)\n",
        "\n",
        "\n",
        "    def f1score(self,y_true,y_pred,average='inter',weights=None):\n",
        "\n",
        "        \"\"\" Computes the f1 score over each given class and returns the overall score.  f1 = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "            # Arguments\n",
        "                y_true : target value\n",
        "                y_pred : predicted class value\n",
        "                average : 'inter' --> computes the f1 score overall  'intra' --> computes the score for each calss and computes the average\n",
        "                            'weighted' --> computes the weighted average , useful for imabalanced class.\n",
        "                weights :  only if average is specified 'weighted', weights for the respective classes.\n",
        "            # Returns\n",
        "                 f1 score\n",
        "        \"\"\"\n",
        "        precision = self.precision(y_true,y_pred,average,weights)\n",
        "        recall = self.recall(y_true,y_pred,average,weights)\n",
        "        return ((2*precision*recall)/(precision+recall))\n",
        "\n",
        "\n",
        "\n",
        "    def dice_coeffiecient(self,y_true,y_pred,average='inter',weights=None):\n",
        "        \"\"\" Computes the dice score over each given class and returns the overall score.\n",
        "\n",
        "                # Arguments\n",
        "                    y_true : target value\n",
        "                    y_pred : predicted class value\n",
        "                    average : 'inter' --> computes the dice score overall  'intra' --> computes the score for each calss and computes the average\n",
        "                                    'weighted' --> computes the weighted average , useful for imabalanced class.\n",
        "                    weights :  only if average is specified 'weighted', weights for the respective classes.\n",
        "                # Returns\n",
        "                    dice score\n",
        "                \"\"\"\n",
        "\n",
        "        y_pred = focal_loss.clipping(y_pred)\n",
        "        intersection = 2 * K.sum((y_true * y_pred),axis=(0,1,2))\n",
        "        union = K.sum( (y_true*y_true) + (y_pred*y_pred),axis=(0,1,2))\n",
        "        return self.__avg_method(intersection,union,average,weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB4E1b4V8ezu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## No need to look, its my own function to convert into onehots\n",
        "\n",
        "def data_convert(data1,data2,data3,data4):\n",
        "\n",
        "        ## the function to get one-hot encoded values\n",
        "        #print('\\n converting the images.... \\n')\n",
        "        for i in range(12): data4[(np.where((np.sum(abs(data1 - data2[i]), axis=-1)) == 0))] = data3[i]\n",
        "        return data4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uG8-gmP6eG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c3600e18-71e0-4ec2-fc50-fe7cb1e03771"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_D-U0gh65nP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29903d4f-9cf8-4ca0-c78a-7c62af2f92f2"
      },
      "source": [
        "## no need to look, its for getting the data from drive\n",
        "\n",
        "path_y = \"/content/drive/My Drive/dataset/filtered data/seg_f/\"\n",
        "path_x = \"/content/drive/My Drive/dataset/filtered data/rgb_f/\"\n",
        "\n",
        "n_classes = 12\n",
        "\n",
        "\n",
        "## color map instruction\n",
        "label_value = np.array([[0,0,0],[70,70,70],[153,153,190],[160, 170, 250],[153, 153, 153],[50, 234, 157],[128, 64, 128],[232, 35, 244],[35, 142, 107],[142, 0, 0],[156, 102, 102],[0, 220, 220]])\n",
        "label_class = np.array(['Unlabeled','Building','Fence','Other','Pole','Road line','Road','Sidewalk','Vegetation','Car','Wall','Traffic sign'])\n",
        "\n",
        "\n",
        "## reading the data from image\n",
        "data_y = np.array([cv2.imread(filename,cv2.IMREAD_COLOR) for filename in glob.glob(path_y+'*.png')])\n",
        "data_x = np.array([cv2.imread(filename,cv2.IMREAD_COLOR) for filename in glob.glob(path_x+'*.png')])\n",
        " \n",
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(471, 320, 320, 3)\n",
            "(471, 320, 320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGEEMVJm7QRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,train_y = data_x[0:20],data_y[0:20]\n",
        "val_x,val_y = data_x[21:25],data_y[21:25]\n",
        "\n",
        "\n",
        "data_y_1hot = np.zeros([train_y.shape[0], train_y.shape[1], train_y.shape[2], 12])\n",
        "data1hot = np.zeros([val_y.shape[0], val_y.shape[1], val_y.shape[2], 12])\n",
        "label_1hot = np.identity(12)\n",
        "train_y_1hot = data_convert(train_y, label_value, label_1hot, data_y_1hot)\n",
        "val_y_1hot = data_convert(val_y, label_value, label_1hot, data1hot)\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_DK_nfE3247",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## this is important, the model_definition function which is used in the hyperband\n",
        "## I've defined my model here and used the configurations given from hyperband for each iteration \n",
        "\n",
        "def define(res,params):\n",
        "        '''\n",
        "          Arguments\n",
        "            params : one hyper-parameter configuration,  dtype - numpyarray\n",
        "\n",
        "            res : number of epochs to run the model,   dtype - int\n",
        "        \n",
        "          Returns\n",
        "            metric : the validation metric for the corresponding configuration\n",
        "        '''\n",
        "\n",
        "        model = UNET.unet((320,320,3),n_classes,BatchNorm=False,summary=False)\n",
        "        model = model.build()\n",
        "\n",
        "        print('\\n \\t running the config ',params,' for - ',int(res),' epochs')\n",
        "        \n",
        "        l = lambda x:focal_loss().loss if x == 'focal_loss' else cross_entropy().loss    ## since loss function is HP, im using lambda function to choos b/w diff loss functions\n",
        "        \n",
        "        ## compiling the model as per the given hyperparameter config\n",
        "        optimizer = Adam(learning_rate=float(params[0]),beta_1=float(params[1]),beta_2=float(params[2]))\n",
        "        model.compile(optimizer,loss = l(params[3])  ,metrics=[Metrics().IoU])\n",
        "\n",
        "        ## train the model\n",
        "        train = model.fit(train_x,train_y_1hot,epochs = int(res),batch_size = 8,validation_data=(val_x,val_y_1hot))\n",
        "\n",
        "        metric = train.history['val_IoU']             ## I'm using val-metric for sucessive halving evaluation not loss\n",
        "        return metric[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbrzs9db_kjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a36addd8-1072-4ea3-afbd-13b80e0ec548"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.backend import tensorflow_backend as K\n",
        "\n",
        "config = hyp.search(define)   ## calling the search function from hyperband"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Current bracket number -  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"Unet\", inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \t running the config  ['0.005' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 13s 630ms/step - loss: 13654.8676 - IoU: 0.0946 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.005' '0.9' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 107ms/step - loss: 14562.9699 - IoU: 0.0421 - val_loss: 15769.8193 - val_IoU: 0.0019\n",
            "\n",
            " \t running the config  ['0.0001' '0.9' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 13958.5232 - IoU: 0.0497 - val_loss: 12155.7393 - val_IoU: 0.1229\n",
            "\n",
            " \t running the config  ['0.008' '0.92' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 12016.6916 - IoU: 0.1022 - val_loss: 12612.3926 - val_IoU: 0.1081\n",
            "\n",
            " \t running the config  ['0.005' '0.88' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 15171.0404 - IoU: 0.0166 - val_loss: 15615.2461 - val_IoU: 0.0066\n",
            "\n",
            " \t running the config  ['8e-05' '0.88' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 14488.4951 - IoU: 0.0345 - val_loss: 14862.7686 - val_IoU: 0.0327\n",
            "\n",
            " \t running the config  ['0.001' '0.92' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 109ms/step - loss: 10146.5023 - IoU: 0.1924 - val_loss: 10052.8926 - val_IoU: 0.2122\n",
            "\n",
            " \t running the config  ['1e-05' '0.9' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 14521.4764 - IoU: 0.0321 - val_loss: 13371.6670 - val_IoU: 0.0867\n",
            "\n",
            " \t running the config  ['5e-05' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 13705.7277 - IoU: 0.0534 - val_loss: 12891.1455 - val_IoU: 0.0875\n",
            "\n",
            " \t running the config  ['1e-05' '0.86' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 14423.2912 - IoU: 0.0315 - val_loss: 13743.0352 - val_IoU: 0.0626\n",
            "\n",
            " \t running the config  ['5e-05' '0.88' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 14893.1906 - IoU: 0.0209 - val_loss: 13813.6455 - val_IoU: 0.0696\n",
            "\n",
            " \t running the config  ['0.0001' '0.88' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 13687.9764 - IoU: 0.0764 - val_loss: 11771.8721 - val_IoU: 0.1668\n",
            "\n",
            " \t running the config  ['0.008' '0.86' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 13711.0645 - IoU: 0.0855 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.008' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 14934.1014 - IoU: 0.0312 - val_loss: 15769.8193 - val_IoU: 0.0019\n",
            "\n",
            " \t running the config  ['8e-05' '0.86' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 12907.7127 - IoU: 0.0871 - val_loss: 12621.9873 - val_IoU: 0.1075\n",
            "\n",
            " \t running the config  ['0.0001' '0.88' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 14334.0439 - IoU: 0.0406 - val_loss: 12567.9502 - val_IoU: 0.1201\n",
            "\n",
            " \t running the config  ['5e-05' '0.86' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 109ms/step - loss: 13582.8258 - IoU: 0.0643 - val_loss: 10975.7002 - val_IoU: 0.1686\n",
            "\n",
            " \t running the config  ['8e-05' '0.86' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 107ms/step - loss: 12795.8877 - IoU: 0.1238 - val_loss: 11761.8330 - val_IoU: 0.1677\n",
            "\n",
            " \t running the config  ['8e-05' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 14359.3127 - IoU: 0.0415 - val_loss: 12928.2793 - val_IoU: 0.0907\n",
            "\n",
            " \t running the config  ['0.0008' '0.92' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 13348.6123 - IoU: 0.0967 - val_loss: 11757.2422 - val_IoU: 0.1679\n",
            "\n",
            " \t running the config  ['0.0005' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 12029.4777 - IoU: 0.1382 - val_loss: 10680.6543 - val_IoU: 0.1848\n",
            "\n",
            " \t running the config  ['1e-05' '0.88' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 15122.0396 - IoU: 0.0146 - val_loss: 15760.6230 - val_IoU: 0.0019\n",
            "\n",
            " \t running the config  ['0.001' '0.86' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 10830.1352 - IoU: 0.1724 - val_loss: 9338.4961 - val_IoU: 0.2467\n",
            "\n",
            " \t running the config  ['0.005' '0.86' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 105ms/step - loss: 12372.5494 - IoU: 0.1205 - val_loss: 11765.1006 - val_IoU: 0.1676\n",
            "\n",
            " \t running the config  ['0.01' '0.88' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 104ms/step - loss: 13747.9016 - IoU: 0.0898 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0005' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 13382.5221 - IoU: 0.0928 - val_loss: 11636.0713 - val_IoU: 0.1490\n",
            "\n",
            " \t running the config  ['0.005' '0.92' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 110ms/step - loss: 13511.1311 - IoU: 0.0950 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.01' '0.92' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 14923.0506 - IoU: 0.0287 - val_loss: 15769.8193 - val_IoU: 0.0019\n",
            "\n",
            " \t running the config  ['0.01' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 13312.7088 - IoU: 0.1010 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0005' '0.92' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 10311.3822 - IoU: 0.2042 - val_loss: 9179.6611 - val_IoU: 0.2526\n",
            "\n",
            " \t running the config  ['0.0008' '0.88' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 11834.8840 - IoU: 0.1485 - val_loss: 9938.4932 - val_IoU: 0.2197\n",
            "\n",
            " \t running the config  ['0.008' '0.9' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 105ms/step - loss: 11224.9006 - IoU: 0.1739 - val_loss: 9190.7881 - val_IoU: 0.2519\n",
            "\n",
            " \t running the config  ['0.0001' '0.88' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 11371.6354 - IoU: 0.1494 - val_loss: 10825.3477 - val_IoU: 0.1781\n",
            "\n",
            " \t running the config  ['0.0008' '0.9' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 13476.4363 - IoU: 0.0823 - val_loss: 11507.9746 - val_IoU: 0.1507\n",
            "\n",
            " \t running the config  ['0.01' '0.9' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 110ms/step - loss: 13498.0832 - IoU: 0.0973 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['1e-05' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 15032.4926 - IoU: 0.0192 - val_loss: 14689.0195 - val_IoU: 0.0375\n",
            "\n",
            " \t running the config  ['0.01' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 104ms/step - loss: 12859.3791 - IoU: 0.1180 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.008' '0.88' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 110ms/step - loss: 13890.1621 - IoU: 0.0789 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.01' '0.86' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 13687.1750 - IoU: 0.0879 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0008' '0.92' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 12865.9912 - IoU: 0.0969 - val_loss: 11774.3701 - val_IoU: 0.1402\n",
            "\n",
            " \t running the config  ['0.005' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 105ms/step - loss: 13045.7791 - IoU: 0.1056 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['5e-05' '0.88' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 12538.6551 - IoU: 0.1088 - val_loss: 12615.0586 - val_IoU: 0.1078\n",
            "\n",
            " \t running the config  ['0.0005' '0.86' '0.999' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 12334.2068 - IoU: 0.1312 - val_loss: 10981.2656 - val_IoU: 0.1896\n",
            "\n",
            " \t running the config  ['0.001' '0.86' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 109ms/step - loss: 11066.4602 - IoU: 0.1569 - val_loss: 10262.1221 - val_IoU: 0.2030\n",
            "\n",
            " \t running the config  ['0.001' '0.88' '0.998' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 107ms/step - loss: 9665.7070 - IoU: 0.2283 - val_loss: 9190.8682 - val_IoU: 0.2519\n",
            "\n",
            " \t running the config  ['0.005' '0.9' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 103ms/step - loss: 13583.7432 - IoU: 0.0825 - val_loss: 12612.4336 - val_IoU: 0.1081\n",
            "\n",
            " \t running the config  ['0.008' '0.88' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 13297.7609 - IoU: 0.1050 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0001' '0.9' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 12245.8736 - IoU: 0.1047 - val_loss: 11737.1396 - val_IoU: 0.1367\n",
            "\n",
            " \t running the config  ['0.01' '0.86' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 109ms/step - loss: 12099.7193 - IoU: 0.1437 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0001' '0.9' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 13037.5531 - IoU: 0.0989 - val_loss: 10927.0127 - val_IoU: 0.1920\n",
            "\n",
            " \t running the config  ['0.001' '0.88' '0.997' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 12857.1656 - IoU: 0.1063 - val_loss: 11954.1045 - val_IoU: 0.1530\n",
            "\n",
            " \t running the config  ['0.0005' '0.9' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 13947.6164 - IoU: 0.0712 - val_loss: 13399.1201 - val_IoU: 0.0796\n",
            "\n",
            " \t running the config  ['0.001' '0.88' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 13500.4018 - IoU: 0.0942 - val_loss: 9941.6729 - val_IoU: 0.2168\n",
            "\n",
            " \t running the config  ['0.008' '0.9' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 13665.1553 - IoU: 0.0940 - val_loss: 11761.2725 - val_IoU: 0.1678\n",
            "\n",
            " \t running the config  ['0.0008' '0.88' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 109ms/step - loss: 14071.8396 - IoU: 0.0601 - val_loss: 12795.2920 - val_IoU: 0.1013\n",
            "\n",
            " \t running the config  ['0.008' '0.88' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 108ms/step - loss: 13797.1807 - IoU: 0.0874 - val_loss: 11955.0127 - val_IoU: 0.1531\n",
            "\n",
            " \t running the config  ['0.001' '0.86' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 12664.3178 - IoU: 0.1002 - val_loss: 12612.4326 - val_IoU: 0.1081\n",
            "\n",
            " \t running the config  ['1e-05' '0.92' '0.998' 'cross_entropy']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 14475.1914 - IoU: 0.0372 - val_loss: 15760.9395 - val_IoU: 0.0020\n",
            "\n",
            " \t running the config  ['8e-05' '0.9' '0.997' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 14768.6773 - IoU: 0.0324 - val_loss: 14104.3643 - val_IoU: 0.0544\n",
            "\n",
            " \t running the config  ['0.001' '0.86' '0.999' 'focal_loss']  for -  1  epochs\n",
            "Train on 20 samples, validate on 4 samples\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3ca7be5ac387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-2d4c68465828>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, model_definition, max_iter, eta, skip_last, using_loss)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mn_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no. of configs for given successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mr_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no. of resources for given successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# getting the val_metric for each config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0musing_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# implementing the successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2d4c68465828>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mn_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no. of configs for given successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mr_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no. of resources for given successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# getting the val_metric for each config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0musing_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# implementing the successive halving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3ac18503aa63>\u001b[0m in \u001b[0;36mdefine\u001b[0;34m(res, params)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m## train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_1hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8,64,320,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_59/conv2d_1140/convolution_grad/Conv2DBackpropInput (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_365309]\n\nFunction call stack:\nkeras_scratch_graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WT0uL4K_yrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}